# Neuro Library

<div align="center">

[![Neuro Library Logo](./frontend/static/img/logo.png)](https://neurolibrary.vercel.app)

</div>

<div align="center">

[![License](https://img.shields.io/github/license/ausafulislam/neuro-library)](LICENSE) [![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)](https://www.python.org/) [![TypeScript](https://img.shields.io/badge/TypeScript-5.x-blue?logo=typescript)](https://www.typescriptlang.org/) [![FastAPI](https://img.shields.io/badge/FastAPI-0.116+-green?logo=fastapi)](https://fastapi.tiangolo.com/) [![Docusaurus](https://img.shields.io/badge/Docusaurus-3.x-informational?logo=docusaurus)](https://docusaurus.io/) [![Qdrant](https://img.shields.io/badge/Qdrant-Vector_DB-red)](https://qdrant.tech/) [![Status](https://img.shields.io/badge/Status-Active-success)](https://github.com/ausafulislam/neuro-library)

</div>


**AI-Native Learning Platform for Physical AI & Humanoid Robotics** ğŸ¤–

>_A comprehensive educational resource with RAG-powered AI assistance_


---

Neuro Library is an **AI-native learning platform** for **Physical AI & Humanoid Robotics** education. It provides comprehensive textbook content organized in structured modules covering **ROS 2**, **Digital Twin technologies**, **NVIDIA Isaac**, and **Vision-Language-Action systems** with humanoid robotics. ğŸ“˜

## Overview

The Neuro Library platform is designed as an educational resource for students, engineers, and AI enthusiasts interested in learning about physical AI and humanoid robotics. The platform combines a Docusaurus-based frontend for content delivery with a FastAPI backend that implements RAG (Retrieval-Augmented Generation) capabilities for AI-powered learning assistance.

### Key Features ğŸš€

- ğŸ“˜ **Comprehensive Educational Content**: Structured modules covering ROS 2, Digital Twin, NVIDIA Isaac, and VLA & Humanoids
- ğŸ¤– **AI-Powered Learning Assistance**: RAG-based chatbot for answering questions about textbook content
- ğŸ“± **Responsive Web Interface**: Built with Docusaurus for optimal learning experience across devices
- ğŸ“Š **Modular Learning Path**: Clear progression from fundamentals to advanced topics
- ğŸ’» **Code Examples**: Practical examples and exercises integrated throughout the content
- âš¡ **Performance Optimized**: Fast loading times and responsive user experience

## Architecture ğŸ—ï¸

The project is organized into two main components:

### ğŸ Backend (Python/FastAPI)

Located in the `backend/` directory, the backend provides:

- ğŸ¤– **RAG Server**: Implements Retrieval-Augmented Generation for AI-powered question answering
- ğŸ“¥ **Content Ingestion**: Automatically fetches and processes website content into vector database
- ğŸ” **Vector Database Integration**: Uses Qdrant for efficient similarity search
- ğŸ§  **AI Agent Integration**: Implements AI agents for enhanced learning assistance
- ğŸŒ **API Endpoints**: Provides RESTful APIs for frontend integration

**Key technologies:**
- FastAPI for web framework
- Sentence Transformers for text embeddings
- Qdrant for vector database
- BeautifulSoup for web scraping
- OpenAI agents for AI assistance

### ğŸŒ Frontend (Docusaurus)

Located in the `frontend/` directory, the frontend provides:

- ğŸ“š **Educational Content Platform**: Docusaurus-based static site for textbook content
- ğŸ“± **Responsive Design**: Mobile and desktop optimized reading experience
- ğŸ” **Search Functionality**: Local search across all textbook content
- ğŸ§­ **Navigation Structure**: Organized by modules and chapters as per curriculum
- ğŸ¨ **Branded UI**: Custom "Neuro Library" branding instead of default Docusaurus

**Key technologies:**
- Docusaurus v3.x
- React
- TypeScript
- Custom CSS for styling

## Project Structure

```
Neuro Library/
â”œâ”€â”€ backend/                    # FastAPI backend with RAG capabilities
â”‚   â”œâ”€â”€ main.py                 # Main RAG server implementation
â”‚   â”œâ”€â”€ agent.py                # AI agent for enhanced interactions
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â””â”€â”€ pyproject.toml          # Project configuration
â”œâ”€â”€ frontend/                   # Docusaurus frontend
â”‚   â”œâ”€â”€ docs/                   # Textbook content (modules, chapters)
â”‚   â”œâ”€â”€ src/                    # Custom components and pages
â”‚   â”œâ”€â”€ static/                 # Static assets (images, etc.)
â”‚   â”œâ”€â”€ docusaurus.config.ts    # Docusaurus configuration
â”‚   â””â”€â”€ package.json            # Frontend dependencies
â”œâ”€â”€ specs/                      # Project specifications and requirements
â”‚   â””â”€â”€ 1-neuro-library-platform/ # Feature specification files
â”œâ”€â”€ history/                    # Development history and prompts
â”‚   â””â”€â”€ prompts/                # Prompt history records
â”œâ”€â”€ .specify/                   # SpecKit Plus configuration
â””â”€â”€ README.md                   # This file
```

## Curriculum Structure ğŸ“š

The textbook content is organized into **4 main modules**:

### ğŸ¤– Module 1: ROS 2 (Weeks 3-5)
- Chapter 1: Introduction to ROS 2
- Chapter 2: Nodes and Topics
- Chapter 3: Services, Actions, and Parameters
- Chapter 4: URDF Robot Modeling
- Chapter 5: Launch Files and Package Management

### ğŸŒ Module 2: Digital Twin (Weeks 6-7)
- Chapter 1: Introduction to Gazebo and Unity
- Chapter 2: Physics Simulation
- Chapter 3: Sensor Simulation
- Chapter 4: High-Fidelity Rendering

### âš¡ Module 3: NVIDIA Isaac (Weeks 8-10)
- Chapter 1: Isaac Sim Overview
- Chapter 2: Hardware-Accelerated VSLAM
- Chapter 3: Navigation and Path Planning
- Chapter 4: AI-Powered Perception
- Chapter 5: Reinforcement Learning

### ğŸ¤– Module 4: VLA & Humanoids (Weeks 11-13)
- Chapter 1: Humanoid Robot Development
- Chapter 2: Manipulation and Grasping
- Chapter 3: Human-Robot Interaction
- Chapter 4: Conversational Robotics
- Chapter 5: Capstone - Autonomous Humanoid

## Installation

### Backend Setup

1. Navigate to the backend directory:
```bash
cd backend/
```

2. Create a virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables by creating a `.env` file:
```env
SITEMAP_URL=your_sitemap_url
COLLECTION_NAME=your_collection_name
QDRANT_URL=your_qdrant_url
QDRANT_API_KEY=your_qdrant_api_key
OPEN_ROUTER_API_KEY=your_openrouter_api_key
OPEN_ROUTER_BASE_URL=https://openrouter.ai/api/v1
OPEN_ROUTER_MODEL=model_name
```

5. Run the backend server:
```bash
uvicorn main:app --reload
```

### Frontend Setup

1. Navigate to the frontend directory:
```bash
cd frontend/
```

2. Install dependencies:
```bash
npm install
# or
yarn install
```

3. Start the development server:
```bash
npm run start
# or
yarn start
```

## Usage

1. The backend server will automatically ingest content from the specified sitemap during startup
2. The frontend provides a web interface to browse the textbook content
3. The RAG API endpoint (`/ask`) allows querying the ingested content
4. The AI agent endpoint (`/chat`) provides conversational access to the textbook content

## Configuration

### Environment Variables

The application requires several environment variables to be set:

**Backend:**
- `SITEMAP_URL`: URL to the sitemap containing textbook content
- `COLLECTION_NAME`: Qdrant collection name for storing embeddings
- `QDRANT_URL`: Qdrant vector database URL
- `QDRANT_API_KEY`: Qdrant API key for authentication
- `OPEN_ROUTER_API_KEY`: API key for OpenRouter (if using AI agent)
- `OPEN_ROUTER_BASE_URL`: Base URL for OpenRouter API
- `OPEN_ROUTER_MODEL`: Model name for OpenRouter

## Development

### Adding Content

To add new textbook content:

1. Create new markdown files in the `frontend/docs/` directory following the module/chapter structure
2. Update the sidebar configuration in `frontend/sidebars.ts`
3. Add images to the `frontend/static/img/` directory with descriptive filenames
4. Ensure each content file includes proper metadata (title, description, keywords, sidebar_position)

### API Endpoints

**Backend:**
- `GET /` - Health check endpoint
- `POST /ask` - RAG question answering (returns context and sources)
- `POST /chat` - AI agent conversation endpoint

## Deployment ğŸš€

### Frontend Deployment

The frontend is built for static hosting and can be deployed to platforms like:

- ğŸŸ¦ [Vercel](https://vercel.com/) (recommended, as configured in docusaurus.config.ts)
- ğŸŸ¨ [Netlify](https://www.netlify.com/)
- ğŸŸª [GitHub Pages](https://pages.github.com/)
- ğŸ¤— [Hugging Face Spaces](https://huggingface.co/spaces) (for static sites)
- Any static hosting service

Build command:
```bash
npm run build
```

### Backend Deployment

The backend can be deployed to platforms that support Python applications:

- ğŸŸ¦ [Vercel](https://vercel.com/)
- ğŸŸª [Railway](https://railway.app/)
- ğŸ…±ï¸ [Heroku](https://www.heroku.com/)
- â˜ï¸ [AWS](https://aws.amazon.com/), [GCP](https://cloud.google.com/), or [Azure](https://azure.microsoft.com/)
- ğŸ¤— [Hugging Face Inference API](https://huggingface.co/inference-api) (for API deployment)

## Performance Targets âš¡

- â±ï¸ **Page load time**: < 3 seconds
- ğŸ–¼ï¸ **Largest Contentful Paint**: < 2.5s
- ğŸ“ **Cumulative Layout Shift**: < 0.1
- ğŸ“± **Responsive design**: Optimized for all device sizes

## Contributing ğŸ¤

We welcome contributions from the community! Here's how you can help:

1. ğŸ´ **Fork** the repository
2. ğŸŒŸ **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. âœï¸ **Make** your changes
4. ğŸ’¾ **Commit** your changes (`git commit -m 'Add amazing feature'`)
5. ğŸ“¤ **Push** to the branch (`git push origin feature/amazing-feature`)
6. ğŸ”„ **Open** a Pull Request

## License ğŸ“„

This project is licensed under the terms specified in the project documentation.

## Support ğŸ›Ÿ

For support, please open an issue in the GitHub repository or contact the development team.

## About â„¹ï¸

<div align="center">

**Neuro Library** was developed as part of a **Spec-Driven Hackathon** by **Ausaf ul Islam**.

The platform follows the principles of **Spec-Driven Development (SDD)** and implements an **AI-native approach** to technical education. ğŸ¯

</div>

<div align="center">

ğŸ¤– **Physical AI & Humanoid Robotics Education** | ğŸ§  **AI-Powered Learning** | ğŸ“˜ **Comprehensive Textbook Content**

</div>